{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. 获取事件链正例\n",
    "\n",
    "遍历事件树，构造长度为5的事件链"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 从corpus中读取事件列表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total news number: 221\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "dataset_dir = os.path.join('..', 'corpus')\n",
    "data_list = os.listdir(dataset_dir)\n",
    "\n",
    "print('Total news number:', len(data_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 构造事件链"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def find_all_path(graph, start, end, path=[]):\n",
    "    \"\"\"\n",
    "    遍历图的所有路径\n",
    "    :param graph:\n",
    "    :param start:\n",
    "    :param end:\n",
    "    :param path: 存储路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = path + [start]\n",
    "    if start == end:\n",
    "        return [path]\n",
    "    paths = []  # 存储所有路径\n",
    "    for node in graph[start]:\n",
    "        if graph[start][node] == '并列关系':\n",
    "            continue\n",
    "        if node not in path:\n",
    "            newpaths = find_all_path(graph, node, end, path)\n",
    "            for newpath in newpaths:\n",
    "                paths.append(newpath)\n",
    "    return paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total event chain number: 10445\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "good_event_chain = []\n",
    "\n",
    "for data_file_name in data_list:\n",
    "    try:\n",
    "        # 读取文件内容\n",
    "        data_file_path = os.path.join(dataset_dir, data_file_name)\n",
    "        with open(data_file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.loads(f.read())  # 文件JSON内容\n",
    "\n",
    "        keys = sorted(data['event_relation'].keys())\n",
    "        graph_start = keys[0]\n",
    "        graph_end = data[\"event_element\"][-1][\"event_graph\"][-1][\"child_event_id\"]\n",
    "\n",
    "        # 获取第一句话的event node\n",
    "        first_event_keys = [x[\"child_event_id\"] for x in data[\"event_element\"][0][\"event_graph\"]]\n",
    "\n",
    "        # 获取所有完整事件链\n",
    "        event_chains = []\n",
    "        event_chains = find_all_path(data['event_relation'], graph_start, graph_end, event_chains)\n",
    "\n",
    "        # 获取长度为5的事件链，其中第一个节点属于first_event_keys\n",
    "        ret_event_chains = []\n",
    "        for event_chain in event_chains:\n",
    "            if len(event_chain) < 5:\n",
    "                continue\n",
    "            if event_chain[0] not in first_event_keys:\n",
    "                continue\n",
    "\n",
    "            first_events = [x for x in event_chain if x in first_event_keys]\n",
    "            for i in range(len(event_chain)):\n",
    "                if event_chain[i] in first_events:\n",
    "                    second_events = event_chain[i + 1:]\n",
    "                    tmp_event_chains = list(combinations(second_events, 4))\n",
    "                    tmp_event_chains = [[event_chain[i]] + list(x) for x in tmp_event_chains]\n",
    "                    ret_event_chains += tmp_event_chains\n",
    "\n",
    "        # 事件链去重\n",
    "        ret = []\n",
    "        for event_item in ret_event_chains:\n",
    "            if event_item not in ret:\n",
    "                ret.append(event_item)\n",
    "        news_id = data_file_name.split('_')[0]\n",
    "        ret_event_chains = ret\n",
    "        del ret\n",
    "\n",
    "        # 补充news id\n",
    "        for event_item in ret_event_chains:\n",
    "            good_event_chain.append([news_id + \"_\" + x for x in event_item])\n",
    "    except Exception as e:\n",
    "        print('Find error in', data_file_name)\n",
    "        print(e)\n",
    "print('Total event chain number:', len(good_event_chain))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Done!!!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# with open(os.path.join('..', 'dataset', 'tmp', 'good.data'), 'w', encoding='utf-8') as f:\n",
    "#     for chain in good_event_chain:\n",
    "#         f.write('\\t'.join(chain) + '\\n')\n",
    "# good_event_chain = good_event_chain[:10]\n",
    "print('Done!!!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['0835_e01', '0835_e02', '0835_e04', '0835_e05', '0835_e06']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# for item in good_event_chain:\n",
    "#     if len(item) != 5:\n",
    "#         print('error')\n",
    "print(good_event_chain[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 通过正例获取事件链负例\n",
    "\n",
    "将正例事件链的最后一个事件替换为错误的事件（在这里调整正负比）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "50\n",
      "9\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ids = []\n",
    "for event_id in good_event_chain:\n",
    "    ids += event_id\n",
    "print(len(ids))\n",
    "ids = list(set(ids))\n",
    "print(len(ids))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'child_event_id': 'e01', 'trigger_agent': '旅行车与货车', 'trigger': '发生', 'trigger_object': '追尾事故', 'agent_attri': '一辆由北京中国青年年旅行社组织/载有德籍旅客的北京牌照中型', 'object_attri': '特大', 'time': '2012年10月1日上午8时30分', 'time_align': '2015-10-01-08-30', 'location': '京津塘高速公路下行54公里处', 'organization': '', 'person': ''}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def check_node(event_info):\n",
    "    news_id, event_id = event_info.split('_')[0],event_info.split('_')[1]\n",
    "    for file_name in data_list:\n",
    "        if file_name.split('_')[0] == news_id:\n",
    "            with open(os.path.join(dataset_dir,file_name) , 'r', encoding='utf-8') as f:\n",
    "                json_data = json.loads(f.read())\n",
    "            for item in json_data['event_element']:\n",
    "                for node in item['event_graph']:\n",
    "                    if node['child_event_id'] == event_id:\n",
    "                        return node\n",
    "    return None\n",
    "\n",
    "print(check_node('12048_e01'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "40\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "bad_event_chain = []\n",
    "\n",
    "def check_same(events, node):\n",
    "    node_info = check_node(node)\n",
    "    for e in events:\n",
    "        e_info = check_node(e)\n",
    "        if e_info['trigger'] == node_info['trigger']:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for eventchain in good_event_chain:\n",
    "    random.shuffle(ids)\n",
    "    bad_nodes = ids\n",
    "    cnt = 0\n",
    "    for bad_node in bad_nodes:\n",
    "        if cnt >= 4:  # 在这里调整正负比，4表示正负比是4\n",
    "            break\n",
    "        if check_same(eventchain, bad_node):\n",
    "            tmp_event = eventchain[:-1] + [bad_node]\n",
    "#             print(tmp_event)\n",
    "            bad_event_chain.append(tmp_event)\n",
    "            cnt += 1\n",
    "#     break\n",
    "print(len(bad_event_chain))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Done!!!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# with open(os.path.join('..', 'dataset', 'tmp', 'bad.data'), 'w', encoding='utf-8') as f:\n",
    "#     for chain in bad_event_chain:\n",
    "#         f.write('\\t'.join(chain) + '\\n')\n",
    "\n",
    "print('Done!!!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['0835_e01', '0835_e02', '0835_e04', '0835_e05', '0835_e09']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# for item in bad_event_chain:\n",
    "#     if len(item )!= 5:\n",
    "#         print(\"error\")\n",
    "print(bad_event_chain[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 分词\n",
    "\n",
    "对数据中非id字段进行分词，用空格分割存储"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyltp import Segmentor\n",
    "model_dir = os.path.join(\"ltp_data_v3.4.0\")\n",
    "\n",
    "segmentor = Segmentor()\n",
    "segmentor.load(os.path.join(model_dir, \"cws.model\"))\n",
    "\n",
    "\n",
    "for chain in good_event_chain:\n",
    "    for event in chain:\n",
    "        for k in event:\n",
    "            if k != 'id':\n",
    "                event[k] = \" \".join([str(x) for x in segmentor.segment(event[k])])\n",
    "\n",
    "for chain in bad_event_chain:\n",
    "    for event in chain:\n",
    "        for k in event:\n",
    "            if k != 'id':\n",
    "                event[k] = \" \".join([str(x) for x in segmentor.segment(event[k])])\n",
    "                \n",
    "print('finish segment...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 分割数据集\n",
    "\n",
    "train、eval、test （6：2：2）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "good: 10\n",
      "bad: 40\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 将id转化为数据\n",
    "\n",
    "pop_keys = ['child_event_id',\n",
    "            'time',\n",
    "            'time_align',\n",
    "            'location',\n",
    "            'organization',\n",
    "            'person']\n",
    "good_data = []\n",
    "\n",
    "for i in range(len(good_event_chain)):\n",
    "    tmp_chain = []\n",
    "\n",
    "    for item in good_event_chain[i]:\n",
    "        tmp_node = check_node(item)\n",
    "        tmp_node['id'] = item\n",
    "        \n",
    "        for k in pop_keys:\n",
    "            if k in tmp_node.keys():\n",
    "                tmp_node.pop(k)\n",
    "        \n",
    "        tmp_chain.append(tmp_node)\n",
    "    good_data.append(tmp_chain)\n",
    "    \n",
    "bad_data = []\n",
    "for i in range(len(bad_event_chain)):\n",
    "    tmp_chain = []\n",
    "    for item in bad_event_chain[i]:\n",
    "        tmp_node = check_node(item)\n",
    "        tmp_node['id'] = item\n",
    "        for k in pop_keys:\n",
    "            if k in tmp_node.keys():\n",
    "                tmp_node.pop(k)\n",
    "        tmp_chain.append(tmp_node)\n",
    "    bad_data.append(tmp_chain)\n",
    "print(\"good: {}\".format(str(len(good_data))))\n",
    "print(\"bad: {}\".format(str(len(bad_data))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# print(good_data[0])\n",
    "# print(bad_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "eval_data = []\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "good_data = shuffle(good_data)\n",
    "bad_data = shuffle(bad_data)\n",
    "\n",
    "contents = []\n",
    "for item in good_data:\n",
    "    contents.append({\n",
    "        'event':item,\n",
    "        'label':1\n",
    "    })\n",
    "good_data = contents\n",
    "\n",
    "contents = []\n",
    "for item in bad_data:\n",
    "    contents.append({\n",
    "        'event':item,\n",
    "        'label':0\n",
    "    })\n",
    "bad_data = contents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "30\n",
      "10\n",
      "10\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_data = good_data[0: int(0.6*(len(good_data)))] + bad_data[0: int(0.6*(len(bad_data)))]\n",
    "test_data = good_data[int(0.6*(len(good_data))):int(0.8*(len(good_data)))] + bad_data[int(0.6*(len(bad_data))):int(0.8*(len(bad_data)))] \n",
    "eval_data = good_data[int(0.8*(len(good_data))):] + bad_data[int(0.8*(len(bad_data))):]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(eval_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "done\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_data = shuffle(train_data)\n",
    "test_data = shuffle(test_data)\n",
    "eval_data = shuffle(eval_data) \n",
    "    \n",
    "# with open(os.path.join('..','dataset', 'tmp','train.data'),'w',encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(train_data, ensure_ascii=False))\n",
    "# with open(os.path.join('..','dataset', 'tmp','test.data'),'w',encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(test_data, ensure_ascii=False))\n",
    "# with open(os.path.join('..','dataset', 'tmp','eval.data'),'w',encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(eval_data, ensure_ascii=False))\n",
    "print('done')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 划分数据类型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# 事件类型标注\n",
    "\n",
    "event_types = dict()\n",
    "event_types[0] = '爆炸'\n",
    "event_types[1] = '火灾'\n",
    "event_types[2] = '地质 灾害'\n",
    "event_types[3] = '交通 事故'\n",
    "event_types[4] = '人身 伤害'\n",
    "\n",
    "data_ids = {0: [839, 835, 828, 12, 54, 12050, 424, 12051, 4, 855, 859, 852, 840, 851, 829, 815, 19, 12031, 52, 843, 12029, 830, 834, 811, 824, 818, 850, 854, 404, 841, 454, 48, 848, 803, 455, 12037, 402, 817, 415, 437, 833, 18, 801, 45, 816, 9, 826, 853, 1, 858, 27, 856, 44, 16, 59, 431, 17, 831, 860, 846, 823], 1: [37, 12032, 12030, 447, 409, 441, 3, 814, 845, 12044, 836, 12010, 433, 12028, 452, 12023, 11, 414, 857, 820, 39, 57, 812, 822, 438, 60, 849, 427, 12039, 20, 813], 2: [842, 12046, 58, 819, 419, 12035, 449, 805, 12043, 808, 847, 432, 33, 38, 832, 425, 837, 456, 26, 46, 12041, 23, 821, 12033, 806, 35, 12018, 838, 12011, 55, 51, 844, 421, 408, 407, 12047, 12015, 827, 6, 5, 12042, 422, 420, 406], 3: [12048, 429, 15, 450, 8, 49, 24, 36, 53, 453, 12045, 460, 807, 410, 12016, 436, 47, 12038, 12013, 412, 12026, 426, 12017, 22, 804, 459, 29, 12040, 802, 43, 34, 417, 42, 21, 7, 413, 12049, 416, 12019, 411, 40, 458, 13, 405], 4: [418, 31, 440, 28, 10, 446, 435, 41, 439, 50, 442, 32, 12025, 448, 2, 56, 444, 430, 12022, 12014, 30, 401, 428, 443, 809, 810, 12012, 423, 451, 12027, 12034, 12024, 461, 14, 25, 457, 403, 12021, 434, 445, 12020]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "tmp_data = []\n",
    "for item in eval_data:\n",
    "    item_id = int(item['event'][0]['id'].split('_')[0])\n",
    "    type_id = -1\n",
    "    for k in data_ids:\n",
    "        if item_id in data_ids[k]:\n",
    "            type_id = k\n",
    "            break\n",
    "    tmp = item\n",
    "    tmp['event_type'] = event_types[type_id]\n",
    "    tmp_data.append(tmp)\n",
    "eval_data = tmp_data\n",
    "\n",
    "tmp_data = []\n",
    "for item in test_data:\n",
    "    item_id = int(item['event'][0]['id'].split('_')[0])\n",
    "    type_id = -1\n",
    "    for k in data_ids:\n",
    "        if item_id in data_ids[k]:\n",
    "            type_id = k\n",
    "            break\n",
    "    tmp = item\n",
    "    tmp['event_type'] = event_types[type_id]\n",
    "    tmp_data.append(tmp)\n",
    "test_data = tmp_data\n",
    "\n",
    "tmp_data = []\n",
    "for item in train_data:\n",
    "    item_id = int(item['event'][0]['id'].split('_')[0])\n",
    "    type_id = -1\n",
    "    for k in data_ids:\n",
    "        if item_id in data_ids[k]:\n",
    "            type_id = k\n",
    "            break\n",
    "    tmp = item\n",
    "    tmp['event_type'] = event_types[type_id]\n",
    "    tmp_data.append(tmp)\n",
    "train_data = tmp_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "done\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open(os.path.join('..','dataset', '1_4','train.data'),'w',encoding='utf-8') as f:\n",
    "    f.write(json.dumps(train_data, ensure_ascii=False))\n",
    "with open(os.path.join('..','dataset', '1_4','test.data'),'w',encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_data, ensure_ascii=False))\n",
    "with open(os.path.join('..','dataset', '1_4','eval.data'),'w',encoding='utf-8') as f:\n",
    "    f.write(json.dumps(eval_data, ensure_ascii=False))\n",
    "\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}